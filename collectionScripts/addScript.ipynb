{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da548cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "file = sys.argv[1]\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "270658a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fc8efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NLP functions #######\n",
    "\n",
    "tokenize = lambda x: nlp(x)[0]\n",
    "\n",
    "def transcribe(id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(id,languages=['fr'])\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            transcript = YouTubeTranscriptApi.list_transcripts(id).find_transcript(['en']).translate('fr').fetch()\n",
    "        except Exception as e:\n",
    "            return 'error'\n",
    "    return ' '.join([t['text'] for t in transcript])\n",
    "\n",
    "def toList(text):\n",
    "    return [ token.lemma_ \n",
    "            for token in map(tokenize,text.split()) \n",
    "            if (not token.is_stop) and token.is_alpha]\n",
    "\n",
    "def avg(all_groups):\n",
    "    return [statistics.mean(i) for i in zip(*all_groups)]\n",
    "\n",
    "def variance(all_groups):\n",
    "    return [statistics.variance(i) for i in zip(*all_groups)]\n",
    "\n",
    "def listToAvgAndVar(l):\n",
    "    docVectors = [nlp(word).vector.tolist() for word in l]\n",
    "    return pd.DataFrame([avg(docVectors)+variance(docVectors)])\n",
    "\n",
    "def subQuotes(s):\n",
    "    return re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", s)\n",
    "\n",
    "filter_ = lambda word_list : ' '.join([word for word in word_list.split() if word not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fb65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vid_id'] = df.videos.apply(lambda x: x.split('watch?v=')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f6d7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1456/1456 [13:33<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "df['rawText'] = df.vid_id.progress_apply(transcribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c68af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rawText = df.rawText.apply(subQuotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d363373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.rawText != 'error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e97228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1239/1239 [06:41<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "df['clean'] = df.rawText.progress_apply(filter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54919404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_word_count'] = df['rawText'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f88a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./scripted/'+file.split('/')[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
